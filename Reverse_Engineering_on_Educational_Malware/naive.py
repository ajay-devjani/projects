# Details:
# Written by: Ajay Devjani, M.Tech INSE
# Project Co-partner: Rushaan Qureshi, M.Tech INSE
# Supervised by Prof: Makan Pourzandi

# Importing the libraries
import logging
import time
import pandas as pd
from numpy import mean
from sklearn.metrics import accuracy_score
from sklearn.model_selection import train_test_split, KFold, cross_val_score
from sklearn.naive_bayes import GaussianNB
from sklearn.preprocessing import LabelEncoder


# Function definition to calculate accuracy of "Gaussian Naive Bayes".
# Input: size: Specifies size of n-gram.
# Input: is_dynamic: Specifies whether it is static or dynamic analysis.
# Output: List of accuracies of Gaussian Naive Bayes Analysis (consists of all n-grams and folds).
def gaussian_naive(size=3, is_dynamic=False):
    logging.basicConfig(filename='reverse_engineering.log', level=logging.INFO)
    # Importing the dataset according to Static/Dynamic Analysis.
    if is_dynamic:
        dataset = pd.read_csv('./training/training_dynamic_' + str(size) + '_gram.txt')
        rep_type = 'Dynamic '
    else:
        dataset = pd.read_csv('./training/training_' + str(size) + '_gram.txt')
        rep_type = 'Static '
    # Taking first column of CSV as API sequence (separated with bar: '|')
    # For more details, refer n_grams_creator.py and dynamic_csv_txt.py.
    api_combination = dataset.iloc[:, 0].values
    # Taking last column as 0 for "Benign" and 1 for "Malware".
    is_malware = dataset.iloc[:, -1].values
    start_time = time.time()
    # Encoding labels
    le = LabelEncoder()
    api_combination_encoded = le.fit_transform(api_combination)
    # Test Train split: 20% test and 80% training data.
    X_train, X_test, y_train, y_test = train_test_split(api_combination_encoded, is_malware, test_size=0.20,
                                                        random_state=0)
    # Training the Naive Bayes model on the Training set
    # Defining Classifier as Gaussian Naive Bayes
    classifier = GaussianNB()
    # Fitting the model.
    classifier.fit(X_train.reshape(-1, 1), y_train)
    # Predicting the Test set results without folds.
    y_pred = classifier.predict(X_test.reshape(-1, 1))
    ac = round(accuracy_score(y_test, y_pred) * 100, 6)
    exec_time = time.time() - start_time
    print(rep_type + "Accuracy of Gaussian Naive Bayes with %d grams: %f" % (size, ac))
    logging.info(rep_type + "Accuracy of Gaussian Naive Bayes with %d grams: %f" % (size, ac))
    print("Execution Time: %f" % exec_time)
    logging.info("Execution Time: %f" % exec_time)
    # Defining folds.
    folds = [5, 10, 20]
    accuracies = [ac]
    for k in folds:
        start_time = time.time()
        # Defining split folds with shuffle.
        cv = KFold(n_splits=k, shuffle=True, random_state=1)
        # Calculating cross validation score of every fold, then taking mean of all validation scores
        # followed by rounding it off to 6 decimal places.
        acc = round(mean(cross_val_score(classifier, api_combination_encoded.reshape(-1, 1), is_malware,
                                         scoring='accuracy', cv=cv, n_jobs=-1)) * 100, 6)
        print('\t' + rep_type + 'Naive Bayes> Folds=%d, Accuracy=%f' % (k, acc))
        logging.info('\t' + rep_type + 'Naive Bayes> Folds=%d, Accuracy=%f' % (k, acc))
        exec_time = time.time() - start_time
        print('\t' + "Execution Time: %f" % exec_time)
        logging.info('\t' + "Execution Time: %f" % exec_time)
        accuracies.append(acc)
    # Returning Accuracy List
    return accuracies
